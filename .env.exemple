# LLM Configuration
LLM_PROVIDER=openai  # or 'litellm', 'anthropic', 'vertex_ai', etc.

LITELLM_MODEL=YOUR_LLM_PROXY_MODEL_HERE
LITELLM_BASE_URL=YOUR_LLM_PROXY_BASE_URL_HERE
LITELLM_API_KEY=YOUR_LLM_PROXY_API_KEY_HERE

LLM_MAX_TOKENS=8000
LLM_TEMPERATURE=0.2

# Vector Store Configuration
EMBEDDING_MODEL=YOUR_EMBEDDING_MODEL_HERE
VECTOR_INDEX_PATH=knowledge_base_flat.index
VECTOR_METADATA_PATH=knowledge_base_metadata.json

# Database Configuration
ENCRYPTION_SECRET=YOUR_ENCRYPTION_SECRET_HERE
DATABASE_PATH=feedback.db
SESSION_DB_PATH=session_history.db

# Server Configuration
SERVER_HOST=127.0.0.1
SERVER_PORT=5000
GRADIO_SHARE=false

# Vertex AI Configuration

VERTEX_PROJECT=YOUR_VERTEX_PROJECT_HERE
VERTEX_LOCATION=europe-west1
VERTEX_CREDENTIALS_PATH=YOUR_VERTEX_CREDENTIALS_PATH_HERE

# Cache Configuration
MAX_CACHE_SIZE=500
MAX_CHUNK_SIZE=50000

# Application Settings
MAX_SESSIONS=10
DEFAULT_LANGUAGE=English